---
title: "创造性思维"
author: "王振"
date: "2024-11-03"
output: html_document
---

```{r 读取学生和创造性思维文件}
# 加载 haven 包  
library(haven)  

# 定义你的文件路径  
file1 <- "C:\\Users\\王振\\Desktop\\CY08MSP_STU_QQQ.SAV" 
file2 <- "C:\\Users\\王振\\Desktop\\CY08MSP_CRT_COG.SAV"  

# 读取文件  
data1 <- read_sav(file1)  
data2 <- read_sav(file2)  

# 检查读取的数据，并显示成功消息  
if (!is.null(data1) & !is.null(data2)) {  
  print("两个文件读取成功！")  
} else {  
  print("文件读取失败！")  
}
```


```{r 读取教师与学校数据}
# 加载 haven 包  
library(haven)  

# 定义你的文件路径  
file1 <- "C:\\Users\\王振\\Desktop\\CY08MSP_TCH_QQQ.SAV" 
file2 <- "C:\\Users\\王振\\Desktop\\CY08MSP_SCH_QQQ.SAV"  

# 读取文件  
data3 <- read_sav(file1)  
data4 <- read_sav(file2)  

# 检查读取的数据，并显示成功消息  
if (!is.null(data1) & !is.null(data2)) {  
  print("两个文件读取成功！")  
} else {  
  print("文件读取失败！")  
}
```


```{r 合并学生与创造性思维数据}
library(dplyr)  
# 确保 CNTSTUID 在 data1 和 data2 中存在  
if ("CNTSTUID" %in% names(data1) & "CNTSTUID" %in% names(data2)) {  
  
    # 提取 data2 中的 CNTSTUID 值  
    cntstuid_values <- data2$CNTSTUID  
    
    # 在 data1 中找到与 data2 中相同 CNTSTUID 的整行数据  
    matched_rows <- data1 %>%  
      filter(CNTSTUID %in% cntstuid_values)  
    
    # 使用 match() 函数确保按 data2 中 CNTSTUID 的顺序排列  
    matched_rows <- matched_rows[match(cntstuid_values, matched_rows$CNTSTUID), ]  
    
    # 将提取的行添加到 data2 的后面  
    data2_extended <- bind_cols(data2, matched_rows)  
    
    # 打印出合并后的数据框的前几行以确认结果  
    print(head(data2_extended))  
} else {  
    print("CNTSTUID 在数据中未找到！")  
}
```


```{r 合并创造性思维、学生、家庭、学校数据}
# 假设 data2_extended 和 data4 已经被读取并存在  

# 进行合并，使用 data2_extended 中的 CNTSCHID...3 和 data4 中的 CNTSCHID 进行连接  
merged_data <- merge(data2_extended, data4, by.x = "CNTSCHID...3", by.y = "CNTSCHID", all.x = TRUE)  

# 输出合并后的数据框  
print(merged_data)
```


```{r 复制数据}
data副本5<-merged_data
```


```{r 性别差异}
t_result <- t.test(PV1CRTH_NC ~ as.factor(ST004D01T), data = data副本3, subset = ST004D01T %in% c(1, 2))  
print(t_result) 
```



```{r 标准差}
library(dplyr)  

# 计算 ST004D01T 为 1 和 2 时 PV1CRTH_NC 的标准差  
std_dev_results <- data副本5 %>%  
  filter(ST004D01T %in% c(1, 2)) %>%  # 过滤 ST004D01T 为 1 和 2 的数据  
  group_by(ST004D01T) %>%              # 按 ST004D01T 分组  
  summarise(std_dev = sd(PV1CRTH_NC, na.rm = TRUE),  # 计算标准差，去除缺失值  
            count = n(),                # 计算每组的数量  
            .groups = 'drop')          # 不保留分组  

# 查看结果  
print(std_dev_results)
```


```{r 年级频数分布表}
# 使用table函数统计ST001D01T的频数  
freq_table <- table(data副本5$ST001D01T)  
  
# 打印频数表  
print(freq_table)  
  
# 如果你还想知道有几个不同的取值，可以使用length函数  
number_of_values <- length(freq_table)  
print(paste("ST001D01T有", number_of_values, "个不同的取值。"))  
  
# 如果你想以更友好的方式查看数据，可以将结果转换为数据框  
freq_data2 <- as.data.frame(freq_table)  
colnames(freq_data2) <- c("Value", "Frequency")  
print(freq_data2)
```


```{r 不同年级性别差异}
# 自定义显著性检验函数  
test_significance <- function(data, var_group, var_factor, var_response) {  
  # 检查数据是否足够进行t检验  
  if (length(unique(data[[var_factor]])) < 2 || any(table(data[[var_factor]]) < 2)) {  
    warning("因子水平不足或某些水平下的样本量不足，无法进行t检验。")  
    return(NA)  
  }  
    
  # 执行t检验  
  result <- t.test(data[[var_response]] ~ data[[var_factor]], data = data)  
    
  # 返回t检验结果  
  return(result)  
}  

group_7 <- data副本5 %>%  
  filter(ST001D01T == 7)  
  
result_7 <- test_significance(group_7, "ST001D01T", "ST004D01T", "PV1CRTH_NC")  
print(paste("ST001D01T = 7的结果："))  
print(result_7)  

# 对ST001D01T取值是8的小组进行分析  
group_8 <- data副本5 %>%  
  filter(ST001D01T == 8)  
  
result_8 <- test_significance(group_8, "ST001D01T", "ST004D01T", "PV1CRTH_NC")  
print(paste("ST001D01T = 8的结果："))  
print(result_8)  
  
# 对ST001D01T取值是9的小组进行分析  
group_9 <- data副本5 %>%  
  filter(ST001D01T == 9)  
  
result_9 <- test_significance(group_9, "ST001D01T", "ST004D01T", "PV1CRTH_NC")  
print(paste("ST001D01T = 9的结果："))  
print(result_9)  
  
# 对ST001D01T取值是10的小组进行分析  
group_10 <- data副本5 %>%  
  filter(ST001D01T == 10)  
  
result_10 <- test_significance(group_10, "ST001D01T", "ST004D01T", "PV1CRTH_NC")  
print(paste("ST001D01T = 10的结果："))  
print(result_10)

group_11 <- data副本5 %>%  
  filter(ST001D01T == 11)  
  
result_11 <- test_significance(group_11, "ST001D01T", "ST004D01T", "PV1CRTH_NC")  
print(paste("ST001D01T = 11的结果："))  
print(result_11)  

group_12 <- data副本5 %>%  
  filter(ST001D01T == 12)  
  
result_12 <- test_significance(group_12, "ST001D01T", "ST004D01T", "PV1CRTH_NC")  
print(paste("ST001D01T = 12的结果："))  
print(result_12)  
```


```{r 性别在各个熟练度水平上的分布}
library(dplyr)  
library(ggplot2)  

# 根据PV1CRTH_NC计算熟练水平  
data副本5$Level <- with(data副本5, ifelse(PV1CRTH_NC >= 48, "低于1级",  
                   ifelse(PV1CRTH_NC >= 41 & PV1CRTH_NC < 48, "6级",  
                   ifelse(PV1CRTH_NC >= 32 & PV1CRTH_NC < 41, "5级",  
                   ifelse(PV1CRTH_NC >= 23 & PV1CRTH_NC < 32, "4级",  
                   ifelse(PV1CRTH_NC >= 15 & PV1CRTH_NC < 23, "3级",  
                   ifelse(PV1CRTH_NC >= 6 & PV1CRTH_NC < 15, "2级", "1级")))))))  

# 将 Level 列转换为有序因子  
data副本5$Level <- factor(data副本5$Level, levels = c("低于1级", "1级", "2级", "3级", "4级", "5级", "6级"))  

# 计算 ST004D01T 为 1 和 2 时每个熟练水平的比例  
level_proportions_st1 <- data副本5 %>%  
  filter(ST004D01T == 1) %>%  
  group_by(Level) %>%  
  summarise(count = n(), .groups = 'drop') %>%  
  mutate(proportion = count / sum(count))  

level_proportions_st2 <- data副本5 %>%  
  filter(ST004D01T == 2) %>%  
  group_by(Level) %>%  
  summarise(count = n(), .groups = 'drop') %>%  
  mutate(proportion = count / sum(count))  

# 合并数据框  
level_proportions <- bind_rows(  
  mutate(level_proportions_st1, ST004D01T = "1"),  
  mutate(level_proportions_st2, ST004D01T = "2")  
)  

# 可视化，使用堆叠条形图  
ggplot(level_proportions, aes(x = Level, y = proportion, fill = ST004D01T)) +  
  geom_bar(stat = "identity") +  # 默认是堆叠图  
  geom_text(aes(label = scales::percent(proportion, accuracy = 1)),   
            vjust = -0.5,   
            position = position_stack(vjust = 0.5)) +  # 可以使用position_stack调整文本位置  
  labs(title = "性别在创造性思维的各个熟练水平比例",   
       x = "熟练水平",   
       y = "比例") +  
  theme_minimal() +  
  scale_fill_manual(values = c("1" = "yellow", "2" = "green"),  
                    labels = c("性别", "女", "男")) +   
  scale_fill_discrete(name = "性别",   
                      breaks = c("1", "2"),   
                      labels = c("女", "男"))
```



```{r 邻近法}
# 加载必要的包  
library(MatchIt)  
library(dplyr)  
library(tableone)  

# 定义变量  
treatment_var <- "ST004D01T"  # 处理变量  
outcome_var <- "PV1CRTH_NC"    # 结果变量  
confounders <- c("PV1MATH", "PV1READ", "PV1SCIE",   
                 "CREATEFF", "IMAGINE", "CURIOAGR",   
                 "CREATOP", "OPENART", "PERSEVAGR",   
                 "EFFORT1", "GROSAGR", "CREATSCH",   
                 "CREATFAM", "CREATAS", "CREATOOS",   
                 "CREACTIV", "CREENVSC", "OPENCUL",   
                 "ACTCRESC", "BCREATSC", "CREATHME",   
                 "CREATOPN", "CREATOR", "ESCS",   
                 "CREATACT")  

# 1. 剔除缺失值  
# 保留所有指定变量（处理变量、结果变量和混杂变量）没有缺失值的行  
data_cleaned <- data副本5 %>%  
  filter(complete.cases(select(., all_of(c(treatment_var, outcome_var, confounders)))))  

# 2. 估计倾向得分  
# 将处理变量转换为因子，方便逻辑回归建模  
data_cleaned[[treatment_var]] <- as.factor(data_cleaned[[treatment_var]])  

# 建立逻辑回归模型来估计倾向得分  
ps_model <- glm(as.formula(paste(treatment_var, "~", paste(confounders, collapse = "+"))),  
                data = data_cleaned,  
                family = binomial)  

# 计算倾向得分  
data_cleaned$propensity_score <- predict(ps_model, type = "response")  

# 3. 进行倾向得分匹配  
matched_data <- matchit(as.formula(paste(treatment_var, "~ propensity_score")),  
                        data = data_cleaned,  
                        method = "nearest")  

# 取得匹配后的数据集  
matched_data_df <- match.data(matched_data)  

# 4. 检查匹配质量  
balance_table_before <- CreateTableOne(vars = confounders,   
                                        strata = treatment_var,   
                                        data = data_cleaned,   
                                        test = FALSE)  
balance_table_after <- CreateTableOne(vars = confounders,   
                                       strata = treatment_var,   
                                       data = matched_data_df,   
                                       test = FALSE)  

# 输出匹配前后的平衡性比较  
print("匹配前变量的平衡性：")  
print(balance_table_before, showAll = TRUE)  
print("匹配后变量的平衡性：")  
print(balance_table_after, showAll = TRUE)  

# 5. 结果分析  
# 对匹配后的数据进行线性回归分析，评估处理效果  
outcome_model <- lm(as.formula(paste(outcome_var, "~", treatment_var)),   
                    data = matched_data_df)  
summary(outcome_model)
```


```{r 半径法}
# 加载必要的包  
library(MatchIt)  
library(dplyr)  
library(tableone)  

# 定义变量  
treatment_var <- "ST004D01T"  # 处理变量  
outcome_var <- "PV1CRTH_NC"    # 结果变量  
confounders <- c("PV1MATH", "PV1READ", "PV1SCIE",   
                 "CREATEFF", "IMAGINE", "CURIOAGR",   
                 "CREATOP", "OPENART", "PERSEVAGR",   
                 "EFFORT1", "GROSAGR", "CREATSCH",   
                 "CREATFAM", "CREATAS", "CREATOOS",   
                 "CREACTIV", "CREENVSC", "OPENCUL",   
                 "ACTCRESC", "BCREATSC", "CREATHME",   
                 "CREATOPN", "CREATOR", "ESCS",   
                 "CREATACT")  

# 1. 剔除缺失值  
# 保留所有指定变量（处理变量、结果变量和混杂变量）没有缺失值的行  
data_cleaned <- data副本5 %>%  
  filter(complete.cases(select(., all_of(c(treatment_var, outcome_var, confounders)))))  

# 2. 估计倾向得分  
# 将处理变量转换为因子  
data_cleaned[[treatment_var]] <- as.factor(data_cleaned[[treatment_var]])  

# 建立逻辑回归模型来估计倾向得分  
ps_model <- glm(as.formula(paste(treatment_var, "~", paste(confounders, collapse = "+"))),  
                data = data_cleaned,  
                family = binomial)  

# 计算倾向得分  
data_cleaned$propensity_score <- predict(ps_model, type = "response")  

# 3. 进行倾向得分匹配（使用最近邻法和半径约束）  
caliper_size <- 0.1  # 设置半径的大小，根据数据的具体情况进行调整  

matched_data <- matchit(as.formula(paste(treatment_var, "~ propensity_score")),  
                        data = data_cleaned,  
                        method = "nearest",  
                        caliper = caliper_size)  

# 取得匹配后的数据集  
matched_data_df <- match.data(matched_data)  

# 4. 检查匹配质量  
balance_table_before <- CreateTableOne(vars = confounders,   
                                        strata = treatment_var,   
                                        data = data_cleaned,   
                                        test = FALSE)  
balance_table_after <- CreateTableOne(vars = confounders,   
                                       strata = treatment_var,   
                                       data = matched_data_df,   
                                       test = FALSE)  

# 输出匹配前后的平衡性比较  
print("匹配前变量的平衡性：")  
print(balance_table_before, showAll = TRUE)  
print("匹配后变量的平衡性：")  
print(balance_table_after, showAll = TRUE)  

# 5. 结果分析  
# 对匹配后的数据进行线性回归分析，评估处理效果  
outcome_model <- lm(as.formula(paste(outcome_var, "~", treatment_var)),   
                    data = matched_data_df)  
summary(outcome_model)
```
